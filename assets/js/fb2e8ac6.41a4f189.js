"use strict";(self.webpackChunkdataphilly=self.webpackChunkdataphilly||[]).push([[1938],{855:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>c,frontMatter:()=>s,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"events/2025/june","title":"June 2025 Events","description":"Flyer","source":"@site/docs/events/2025/june.md","sourceDirName":"events/2025","slug":"/events/2025/june","permalink":"/docs/events/2025/june","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"June 2025 Events","sidebar_label":"June"},"sidebar":"docsSidebar","previous":{"title":"July","permalink":"/docs/events/2025/july"},"next":{"title":"May","permalink":"/docs/events/2025/may"}}');var i=t(4848),o=t(8453);const s={title:"June 2025 Events",sidebar_label:"June"},r=void 0,l={},d=[{value:"Speakers:",id:"speakers",level:2}];function u(e){const n={a:"a",br:"br",h2:"h2",img:"img",p:"p",strong:"strong",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://secure.meetupstatic.com/photos/event/d/0/5/b/highres_528293339.webp?w=750",alt:"Flyer"})}),"\n",(0,i.jsx)(n.p,{children:"\ud83d\ude80 Join Us for DataPhilly\u2019s June Talks at ZeroEyes! \ud83d\ude80\nWe fill learn about optimizing AI: From Efficient Deep Learning to Open Multilingual Vision-LLMs.\nOur host is ZeroEyes - company that delivers a proactive, human-verified visual gun detection and situational awareness solution that integrates into existing digital security cameras to stop mass shootings and gun-related violence.\nOur food sponsor is Liberty Personnel, widely recognized as the finest direct placement and contract recruiting firm in the region."}),"\n",(0,i.jsxs)(n.p,{children:["Event Schedule:\nDoors opens at 6:00 pm ET",(0,i.jsx)(n.br,{}),"\n","6:00 - 6:30 Event start and networking, DataPhilly intro",(0,i.jsx)(n.br,{}),"\n",'6:30 - 7:15 Dave Ramsey: "The Neural Net Diet Plan: Cutting Parameters and GFOPs not performance", followed by Q&A',(0,i.jsx)(n.br,{}),"\n","7:15 - 8:00 Karthik reddy Kanjula: \u201cMaya: An Instruction Finetuned Multilingual Multimodal Mode\u201d , followed by Q&A",(0,i.jsx)(n.br,{}),"\n","After 8:00 Networking time"]}),"\n",(0,i.jsx)(n.h2,{id:"speakers",children:"Speakers:"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Dave Ramsey"}),', machine learning engineer at ZeroEyes: "The Neural Net Diet Plan: Cutting Parameters and GFOPs not performance".\nHow to make deep learning models faster and smaller using techniques like distillation, pruning, quantization, Ghost convolutions, and Reparameterization. Perfect for anyone looking to deploy efficient AI without losing accuracy.']}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Summary:"})," This talk dives into the practical techniques used to shrink, speed up, and streamline deep learning models for real-world deployment. We'll explore convolutions, model distillation, pruning, quantization (including QAT), Ghost convolutions, and reparameterization strategies\u2014each offering a different angle on how to maintain accuracy while cutting down size and latency. You'll also get a look at how these methods fit into modern workflows, from training to edge deployment, and how neural architecture search (NAS) can automate some of the process. Whether you're building for mobile, embedded systems, or just want faster inference, this talk offers a toolkit of optimization techniques grounded in real R&D experience."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Speaker Bio:"})," Dave C. Ramsey is a machine learning engineer and jazz trumpet player based in Philadelphia. He began his journey into AI during the COVID shutdown, where a FastAI course hooked him on the parallels between machine learning programming and jazz composition. At ZeroEyes, his work includes cutting-edge model optimization, and image generation using tools like Stable Diffusion and computer vision models. Dave has also helped organize Data Philly meetups running FastAI study groups from time to time helping others break into the field. His work blends creativity and precision, with a passion for building efficient, high-performing models for real-world deployment."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Karthik reddy Kanjula"}),", AI Researcher (Cohere Labs Community, WCUPA),",(0,i.jsx)(n.a,{href:"https://www.x.com/karthik_kanjula",children:"https://www.x.com/karthik_kanjula"})," : \u201cMaya: An Instruction Finetuned Multilingual Multimodal Model\u201d.\nMaya \u2013 A Multimodal Multilingual Vision-LLM built in the open. Maya is completely open source, open weight and open dataset, designed to handle 8 languages, cultural diversity, and nuanced real-world contexts in vision-language models."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Summary:"})," The rapid development of large Vision-Language Models (VLMs) has led to impressive results on academic benchmarks, primarily in widely spoken languages. However, significant gaps remain in the ability of current VLMs to handle low-resource languages and varied cultural contexts, largely due to a lack of high-quality, diverse, and safety-vetted data. Consequently, these models often struggle to understand low-resource languages and cultural nuances in a manner free from toxicity. To address these limitations, we introduce Maya, an open-source Multimodal Multilingual model. Our contributions are threefold: 1) a multilingual image-text pretraining dataset in eight languages, based on the LLaVA pretraining dataset; 2) a thorough analysis of toxicity within the LLaVA dataset, followed by the creation of a novel toxicity-free version across eight languages; and 3) a multilingual image-text model supporting these languages, enhancing cultural and linguistic comprehension in vision-language tasks."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Speaker Bio:"})," I'm Karthik, an AI Researcher, and I hold a master\u2019s degree in computer science from Westchester University of Pennsylvania. Over the years, I\u2019ve immersed myself in AI, computer vision, and data science. Currently, I lead the team for Maya, an innovative open-source multimodal and multilingual AI project from Cohere Labs community. My background includes collaborative research with Penn State University focused on edge computing, and my research journey began by analyzing abnormal epilepsy seizures."]})]})}function c(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>r});var a=t(6540);const i={},o=a.createContext(i);function s(e){const n=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);